{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Mnist_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagtapuday/Mnist_Model/blob/main/Mnist_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oETNIP1Gn-MQ",
        "outputId": "2c15dea8-666f-4791-9e3e-15510d9f9fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK5qnrxnom5F"
      },
      "source": [
        "import os\n",
        "import os.path as path\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "# from keras.layers import Input, Dense, Dropout, Flatten\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "# from keras import backend as K\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense,MaxPooling2D,Dropout\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.python.tools import optimize_for_inference_lib"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxYVLIqbom5L"
      },
      "source": [
        "\n",
        "MODEL_NAME = 'mnist_convnet'\n",
        "EPOCHS = 40\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJKUePPCom5P"
      },
      "source": [
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    y_train = keras.utils.to_categorical(y_train, 10)\n",
        "    y_test = keras.utils.to_categorical(y_test, 10)\n",
        "    return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47ntva4yom5S"
      },
      "source": [
        "\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=64, kernel_size=3, strides=1, \\\n",
        "            padding='same', activation='relu', \\\n",
        "            input_shape=[28, 28, 1]))\n",
        "    # 28*28*64\n",
        "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "    # 14*14*64\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=1, \\\n",
        "            padding='same', activation='relu'))\n",
        "    # 14*14*128\n",
        "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "    # 7*7*128\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, \\\n",
        "            padding='same', activation='relu'))\n",
        "    # 7*7*256\n",
        "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "    # 4*4*256\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Uj-8jcom5V"
      },
      "source": [
        "\n",
        "def train(model, x_train, y_train, x_test, y_test):\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, \\\n",
        "                  optimizer=keras.optimizers.Adadelta(), \\\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(x_train, y_train, \\\n",
        "              batch_size=BATCH_SIZE, \\\n",
        "              epochs=EPOCHS, \\\n",
        "              verbose=1, \\\n",
        "              validation_data=(x_test, y_test))"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2NKX0-Uom5o"
      },
      "source": [
        "def main():\n",
        "    if not path.exists('out'):\n",
        "        os.mkdir('out')\n",
        "\n",
        "    x_train, y_train, x_test, y_test = load_data()\n",
        "\n",
        "    model = build_model()\n",
        "\n",
        "    train(model, x_train, y_train, x_test, y_test)\n",
        "\n",
        "    #export_model(tf.train.Saver(), model, [\"conv2d_1_input\"], \"dense_2/Softmax\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "c2-JHYG8om5x",
        "outputId": "7425c3b4-c4f9-48ed-a34e-89c88fa053d3"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 3s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.2177 - accuracy: 0.9309 - val_loss: 0.0515 - val_accuracy: 0.9832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow_core._api.v2.train' has no attribute 'Saver'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-12-f18e333e5022>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mexport_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"conv2d_1_input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dense_2/Softmax\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.train' has no attribute 'Saver'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR_PM4umom54",
        "outputId": "2e475926-3b30-4d31-a5de-b4fcf12a6b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train, y_train, x_test, y_test = load_data()\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wzGBk6mhEAp",
        "outputId": "704f04a8-3eb3-4b53-bede-0e149ee3b4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(model, x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.2966 - accuracy: 0.1336 - val_loss: 2.2874 - val_accuracy: 0.2010\n",
            "Epoch 2/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.2805 - accuracy: 0.2256 - val_loss: 2.2707 - val_accuracy: 0.4849\n",
            "Epoch 3/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.2631 - accuracy: 0.3217 - val_loss: 2.2515 - val_accuracy: 0.5994\n",
            "Epoch 4/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.2421 - accuracy: 0.3947 - val_loss: 2.2276 - val_accuracy: 0.6266\n",
            "Epoch 5/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.2156 - accuracy: 0.4397 - val_loss: 2.1957 - val_accuracy: 0.6408\n",
            "Epoch 6/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.1787 - accuracy: 0.4881 - val_loss: 2.1504 - val_accuracy: 0.6593\n",
            "Epoch 7/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.1264 - accuracy: 0.5269 - val_loss: 2.0851 - val_accuracy: 0.6810\n",
            "Epoch 8/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.0486 - accuracy: 0.5679 - val_loss: 1.9873 - val_accuracy: 0.7081\n",
            "Epoch 9/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.9339 - accuracy: 0.5976 - val_loss: 1.8418 - val_accuracy: 0.7314\n",
            "Epoch 10/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.7689 - accuracy: 0.6249 - val_loss: 1.6381 - val_accuracy: 0.7515\n",
            "Epoch 11/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.5609 - accuracy: 0.6489 - val_loss: 1.3938 - val_accuracy: 0.7747\n",
            "Epoch 12/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.3357 - accuracy: 0.6830 - val_loss: 1.1565 - val_accuracy: 0.7872\n",
            "Epoch 13/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.1354 - accuracy: 0.7117 - val_loss: 0.9640 - val_accuracy: 0.8048\n",
            "Epoch 14/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.9828 - accuracy: 0.7358 - val_loss: 0.8223 - val_accuracy: 0.8170\n",
            "Epoch 15/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.8647 - accuracy: 0.7613 - val_loss: 0.7187 - val_accuracy: 0.8314\n",
            "Epoch 16/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.7732 - accuracy: 0.7817 - val_loss: 0.6407 - val_accuracy: 0.8456\n",
            "Epoch 17/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.7041 - accuracy: 0.7972 - val_loss: 0.5811 - val_accuracy: 0.8564\n",
            "Epoch 18/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6489 - accuracy: 0.8106 - val_loss: 0.5330 - val_accuracy: 0.8648\n",
            "Epoch 19/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6000 - accuracy: 0.8260 - val_loss: 0.4940 - val_accuracy: 0.8737\n",
            "Epoch 20/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5625 - accuracy: 0.8365 - val_loss: 0.4609 - val_accuracy: 0.8798\n",
            "Epoch 21/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5288 - accuracy: 0.8446 - val_loss: 0.4315 - val_accuracy: 0.8899\n",
            "Epoch 22/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5000 - accuracy: 0.8549 - val_loss: 0.4079 - val_accuracy: 0.8935\n",
            "Epoch 23/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4723 - accuracy: 0.8625 - val_loss: 0.3858 - val_accuracy: 0.9004\n",
            "Epoch 24/40\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.4498 - accuracy: 0.8709 - val_loss: 0.3667 - val_accuracy: 0.9035\n",
            "Epoch 25/40\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.4294 - accuracy: 0.8751 - val_loss: 0.3496 - val_accuracy: 0.9069\n",
            "Epoch 26/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4107 - accuracy: 0.8804 - val_loss: 0.3345 - val_accuracy: 0.9107\n",
            "Epoch 27/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3955 - accuracy: 0.8851 - val_loss: 0.3212 - val_accuracy: 0.9123\n",
            "Epoch 28/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3789 - accuracy: 0.8896 - val_loss: 0.3088 - val_accuracy: 0.9158\n",
            "Epoch 29/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3663 - accuracy: 0.8936 - val_loss: 0.2984 - val_accuracy: 0.9177\n",
            "Epoch 30/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3523 - accuracy: 0.8969 - val_loss: 0.2871 - val_accuracy: 0.9212\n",
            "Epoch 31/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3419 - accuracy: 0.8997 - val_loss: 0.2784 - val_accuracy: 0.9222\n",
            "Epoch 32/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3298 - accuracy: 0.9030 - val_loss: 0.2691 - val_accuracy: 0.9258\n",
            "Epoch 33/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3198 - accuracy: 0.9058 - val_loss: 0.2613 - val_accuracy: 0.9275\n",
            "Epoch 34/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3127 - accuracy: 0.9083 - val_loss: 0.2535 - val_accuracy: 0.9286\n",
            "Epoch 35/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3036 - accuracy: 0.9107 - val_loss: 0.2468 - val_accuracy: 0.9301\n",
            "Epoch 36/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2933 - accuracy: 0.9138 - val_loss: 0.2401 - val_accuracy: 0.9317\n",
            "Epoch 37/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2868 - accuracy: 0.9153 - val_loss: 0.2340 - val_accuracy: 0.9325\n",
            "Epoch 38/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2797 - accuracy: 0.9179 - val_loss: 0.2277 - val_accuracy: 0.9355\n",
            "Epoch 39/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2732 - accuracy: 0.9186 - val_loss: 0.2225 - val_accuracy: 0.9365\n",
            "Epoch 40/40\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2654 - accuracy: 0.9215 - val_loss: 0.2171 - val_accuracy: 0.9378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jHdnbmBom57"
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kyTQV9wom5_"
      },
      "source": [
        "m1 = tf.keras.models.load_model('my_model.h5')"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuX4hZr0k-rC"
      },
      "source": [
        "#!cp -r \"/content/my_model.h5\" \"/content/drive/My Drive/ML/Digit Recognition\""
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTGyOYcvk_He"
      },
      "source": [
        "m1 = tf.keras.models.load_model('/content/drive/My Drive/ML/Digit Recognition/my_model.h5')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66jTBfGmk-69",
        "outputId": "ae34659c-6b4f-48ca-a466-ce3c9692558a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "m1.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 4,575,242\n",
            "Trainable params: 4,575,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C3bcLZ7iC_V"
      },
      "source": [
        "import cv2 \n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuJUw57d2ibr"
      },
      "source": [
        "def Import_Test_Image(path):\n",
        "  img = cv2.imread(path)\n",
        "  print(\"Original Img Shape : \",\"-->\",img.shape)\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "  gray = cv2. cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  gray = np.expand_dims(gray, 2)\n",
        "  gray = gray.astype('float32')\n",
        "  gray/=255.0\n",
        "  print(\"Gray Scale Img Shape -->\",gray.shape)\n",
        "  return gray"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxyMwlfD4QLJ"
      },
      "source": [
        "def Predict(data):\n",
        "  output={}\n",
        "  op_0=m1.predict(data.reshape(1,28,28,1))\n",
        "  for i,val in enumerate(op_0[0]):\n",
        "    output[i]=val\n",
        "  # print(output)\n",
        "  print(\"Top 3 Predicted Results : \",sorted(output, key=output.get, reverse=True)[:3])\n",
        "  "
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jza0UnQGKJ5e",
        "outputId": "e7d6d0de-0aec-4dc1-e0ee-3ce5a0be2f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "img_=Import_Test_Image(\"9.png\")\n",
        "Predict(img_)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Img Shape :  --> (28, 28, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gray Scale Img Shape --> (28, 28, 1)\n",
            "Top 3 Predicted Results :  [9, 7, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSvM1C8O7v-p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}