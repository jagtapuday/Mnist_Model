{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Mnist_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagtapuday/Mnist_Model/blob/main/Mnist_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oETNIP1Gn-MQ",
        "outputId": "1bef11a9-570c-4635-d474-d0facea45aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK5qnrxnom5F"
      },
      "source": [
        "import os\n",
        "import os.path as path\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "# from keras.layers import Input, Dense, Dropout, Flatten\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "# from keras import backend as K\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense,MaxPooling2D,Dropout\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.python.tools import optimize_for_inference_lib"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p32ihTnzTsSG"
      },
      "source": [
        "from tensorflow import lite"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxYVLIqbom5L"
      },
      "source": [
        "\n",
        "MODEL_NAME = 'mnist_convnet'\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJKUePPCom5P"
      },
      "source": [
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255.0\n",
        "    x_test /= 255.0\n",
        "    y_train = keras.utils.to_categorical(y_train, 10)\n",
        "    y_test = keras.utils.to_categorical(y_test, 10)\n",
        "    return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47ntva4yom5S"
      },
      "source": [
        "\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=64, kernel_size=3, strides=1, \\\n",
        "            padding='same', activation='relu', \\\n",
        "            input_shape=[28, 28, 1]))\n",
        "    # 28*28*64\n",
        "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "    # 14*14*64\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=3, strides=1, \\\n",
        "            padding='same', activation='relu'))\n",
        "    # 14*14*128\n",
        "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "    # 7*7*128\n",
        "\n",
        "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, \\\n",
        "            padding='same', activation='relu'))\n",
        "    # 7*7*256\n",
        "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "    # 4*4*256\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Uj-8jcom5V"
      },
      "source": [
        "\n",
        "def train(model, x_train, y_train, x_test, y_test):\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, \\\n",
        "                  optimizer=keras.optimizers.Adadelta(), \\\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(x_train, y_train, \\\n",
        "              batch_size=BATCH_SIZE, \\\n",
        "              epochs=EPOCHS, \\\n",
        "              verbose=1, \\\n",
        "              validation_data=(x_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2NKX0-Uom5o"
      },
      "source": [
        "def main():\n",
        "    if not path.exists('out'):\n",
        "        os.mkdir('out')\n",
        "\n",
        "    x_train, y_train, x_test, y_test = load_data()\n",
        "\n",
        "    model = build_model()\n",
        "\n",
        "    train(model, x_train, y_train, x_test, y_test)\n",
        "\n",
        "    #export_model(tf.train.Saver(), model, [\"conv2d_1_input\"], \"dense_2/Softmax\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "c2-JHYG8om5x",
        "outputId": "7425c3b4-c4f9-48ed-a34e-89c88fa053d3"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 3s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 123s 2ms/step - loss: 0.2177 - accuracy: 0.9309 - val_loss: 0.0515 - val_accuracy: 0.9832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow_core._api.v2.train' has no attribute 'Saver'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-12-f18e333e5022>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mexport_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"conv2d_1_input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dense_2/Softmax\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.train' has no attribute 'Saver'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR_PM4umom54",
        "outputId": "40d5f27d-a0c4-446b-f401-3bbc08038b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train, y_train, x_test, y_test = load_data()\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wzGBk6mhEAp",
        "outputId": "203fde1e-d2f9-487f-d5fb-66b149b2693e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train(model, x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 2.2894 - accuracy: 0.1780 - val_loss: 2.2764 - val_accuracy: 0.2823\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.2639 - accuracy: 0.2795 - val_loss: 2.2494 - val_accuracy: 0.3846\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.2348 - accuracy: 0.3501 - val_loss: 2.2161 - val_accuracy: 0.4917\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.1965 - accuracy: 0.4339 - val_loss: 2.1697 - val_accuracy: 0.5818\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.1408 - accuracy: 0.5178 - val_loss: 2.0999 - val_accuracy: 0.6378\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 2.0545 - accuracy: 0.5820 - val_loss: 1.9891 - val_accuracy: 0.6885\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.9192 - accuracy: 0.6265 - val_loss: 1.8136 - val_accuracy: 0.7151\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.7117 - accuracy: 0.6583 - val_loss: 1.5581 - val_accuracy: 0.7427\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.4466 - accuracy: 0.6840 - val_loss: 1.2676 - val_accuracy: 0.7589\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 1.1915 - accuracy: 0.7118 - val_loss: 1.0248 - val_accuracy: 0.7754\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.9971 - accuracy: 0.7357 - val_loss: 0.8552 - val_accuracy: 0.7968\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.8646 - accuracy: 0.7571 - val_loss: 0.7407 - val_accuracy: 0.8143\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.7685 - accuracy: 0.7785 - val_loss: 0.6571 - val_accuracy: 0.8323\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6969 - accuracy: 0.7975 - val_loss: 0.5945 - val_accuracy: 0.8445\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.6374 - accuracy: 0.8133 - val_loss: 0.5444 - val_accuracy: 0.8571\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5910 - accuracy: 0.8263 - val_loss: 0.5042 - val_accuracy: 0.8694\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5499 - accuracy: 0.8388 - val_loss: 0.4700 - val_accuracy: 0.8781\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5174 - accuracy: 0.8495 - val_loss: 0.4413 - val_accuracy: 0.8852\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4866 - accuracy: 0.8579 - val_loss: 0.4167 - val_accuracy: 0.8903\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4611 - accuracy: 0.8662 - val_loss: 0.3953 - val_accuracy: 0.8956\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4394 - accuracy: 0.8717 - val_loss: 0.3760 - val_accuracy: 0.8999\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4200 - accuracy: 0.8760 - val_loss: 0.3585 - val_accuracy: 0.9040\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4015 - accuracy: 0.8834 - val_loss: 0.3417 - val_accuracy: 0.9058\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3834 - accuracy: 0.8878 - val_loss: 0.3278 - val_accuracy: 0.9099\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3686 - accuracy: 0.8920 - val_loss: 0.3146 - val_accuracy: 0.9135\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3544 - accuracy: 0.8956 - val_loss: 0.3041 - val_accuracy: 0.9144\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3405 - accuracy: 0.9011 - val_loss: 0.2922 - val_accuracy: 0.9173\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3301 - accuracy: 0.9032 - val_loss: 0.2830 - val_accuracy: 0.9198\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.3184 - accuracy: 0.9067 - val_loss: 0.2740 - val_accuracy: 0.9223\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3095 - accuracy: 0.9091 - val_loss: 0.2655 - val_accuracy: 0.9238\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3008 - accuracy: 0.9128 - val_loss: 0.2573 - val_accuracy: 0.9273\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2920 - accuracy: 0.9138 - val_loss: 0.2501 - val_accuracy: 0.9288\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2828 - accuracy: 0.9181 - val_loss: 0.2427 - val_accuracy: 0.9306\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2748 - accuracy: 0.9195 - val_loss: 0.2370 - val_accuracy: 0.9328\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2692 - accuracy: 0.9209 - val_loss: 0.2306 - val_accuracy: 0.9348\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2620 - accuracy: 0.9225 - val_loss: 0.2241 - val_accuracy: 0.9359\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2555 - accuracy: 0.9248 - val_loss: 0.2195 - val_accuracy: 0.9378\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2493 - accuracy: 0.9264 - val_loss: 0.2146 - val_accuracy: 0.9384\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2439 - accuracy: 0.9281 - val_loss: 0.2085 - val_accuracy: 0.9402\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2373 - accuracy: 0.9298 - val_loss: 0.2044 - val_accuracy: 0.9416\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2335 - accuracy: 0.9312 - val_loss: 0.1998 - val_accuracy: 0.9439\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2296 - accuracy: 0.9315 - val_loss: 0.1957 - val_accuracy: 0.9442\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2244 - accuracy: 0.9327 - val_loss: 0.1921 - val_accuracy: 0.9442\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2202 - accuracy: 0.9345 - val_loss: 0.1882 - val_accuracy: 0.9456\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2173 - accuracy: 0.9358 - val_loss: 0.1846 - val_accuracy: 0.9462\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2110 - accuracy: 0.9370 - val_loss: 0.1810 - val_accuracy: 0.9467\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2093 - accuracy: 0.9378 - val_loss: 0.1779 - val_accuracy: 0.9474\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2048 - accuracy: 0.9388 - val_loss: 0.1746 - val_accuracy: 0.9485\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2021 - accuracy: 0.9396 - val_loss: 0.1719 - val_accuracy: 0.9486\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1974 - accuracy: 0.9418 - val_loss: 0.1690 - val_accuracy: 0.9495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jHdnbmBom57"
      },
      "source": [
        "#model.save('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsyqK0EsUuLO"
      },
      "source": [
        "Kears_file=\"Digit_Recognition.h5\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AfcKhMaUkKe"
      },
      "source": [
        "tf.keras.models.save_model(model,Kears_file)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5Zhc-2AVkR2"
      },
      "source": [
        "convertor=lite.TFLiteConverter.from_keras_model(model)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6eqdYNkVkI9",
        "outputId": "2bdfe057-d13c-4144-e573-cbfa73cda366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfmodel=convertor.convert()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpiq0s0csn/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Il1BZhVtjy",
        "outputId": "47044120-3fa6-468c-f358-994efbfa31b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "open(\"Digit_Recognition.tflite\",\"wb\").write(tfmodel)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18304616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kyTQV9wom5_"
      },
      "source": [
        "m1 = tf.keras.models.load_model('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuX4hZr0k-rC"
      },
      "source": [
        "#!cp -r \"/content/Digit_Recognition.h5\" \"/content/drive/My Drive/ML/Digit Recognition\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J5gdb-wX5-L"
      },
      "source": [
        "#!cp -r \"/content/Digit_Recognition.tflite\" \"/content/drive/My Drive/ML/Digit Recognition\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTGyOYcvk_He"
      },
      "source": [
        "m1 = tf.keras.models.load_model('/content/drive/My Drive/ML/Digit Recognition/my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66jTBfGmk-69",
        "outputId": "ae34659c-6b4f-48ca-a466-ce3c9692558a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "m1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 4,575,242\n",
            "Trainable params: 4,575,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C3bcLZ7iC_V"
      },
      "source": [
        "import cv2 \n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuJUw57d2ibr"
      },
      "source": [
        "def Import_Test_Image(path):\n",
        "  img = cv2.imread(path)\n",
        "  print(\"Original Img Shape : \",\"-->\",img.shape)\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "  gray = cv2. cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  gray = np.expand_dims(gray, 2)\n",
        "  gray = gray.astype('float32')\n",
        "  gray/=255.0\n",
        "  print(\"Gray Scale Img Shape -->\",gray.shape)\n",
        "  return gray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxyMwlfD4QLJ"
      },
      "source": [
        "def Predict(data):\n",
        "  output={}\n",
        "  op_0=m1.predict(data.reshape(1,28,28,1))\n",
        "  for i,val in enumerate(op_0[0]):\n",
        "    output[i]=val\n",
        "  # print(output)\n",
        "  print(\"Top 3 Predicted Results : \",sorted(output, key=output.get, reverse=True)[:3])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jza0UnQGKJ5e",
        "outputId": "e7d6d0de-0aec-4dc1-e0ee-3ce5a0be2f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "img_=Import_Test_Image(\"9.png\")\n",
        "Predict(img_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Img Shape :  --> (28, 28, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gray Scale Img Shape --> (28, 28, 1)\n",
            "Top 3 Predicted Results :  [9, 7, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSvM1C8O7v-p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}